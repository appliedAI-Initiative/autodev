import logging
import os
from abc import ABC, abstractmethod
from pathlib import Path
from typing import Union, Optional

from optimum.onnxruntime import ORTModelForCausalLM
from peft import PeftModel
from transformers import AutoModelForCausalLM, PreTrainedModel, PreTrainedTokenizer, AutoTokenizer, AutoConfig

log = logging.getLogger(__name__)


def model_id_to_fn(model_id: str):
    return model_id.replace("/", "--")


def model_id_from_fn(model_fn: str):
    return model_fn.replace("--", "/")


class ModelTransformation(ABC):
    @abstractmethod
    def transform(self, model: AutoModelForCausalLM):
        pass

    def automodel_kwargs(self) -> dict:
        return {}


class ModelTransformationBitsAndBytes8Bit(ModelTransformation):
    """
    Enables the 8-bit transformation from the bitsandbytes library (which must be installed).
    """
    def transform(self, model: AutoModelForCausalLM):
        return model

    def automodel_kwargs(self) -> dict:
        return dict(load_in_8bit=True, device_map="auto")


class ModelTransformationBetterTransformer(ModelTransformation):
    def transform(self, model: PreTrainedModel):
        from optimum.bettertransformer import BetterTransformer
        return BetterTransformer.transform(model)

TModel = Union[PreTrainedModel, PeftModel, ORTModelForCausalLM]


class ModelFactory:
    def __init__(self, base_model_id: str, transformation: Optional[ModelTransformation] = None):
        self.base_model_id = base_model_id
        self.transformation = transformation

    def create_tokenizer(self) -> PreTrainedTokenizer:
        return AutoTokenizer.from_pretrained(self.base_model_id, trust_remote_code=True)

    def create_model(self,
            model_path: Optional[str] = None,
            transformation: Optional[ModelTransformation] = None
        ) -> Union[PreTrainedModel, PeftModel, ORTModelForCausalLM]:
        """
        :param model_path: a path to a directory containing the model/checkpoint to load or
            a path/identifier known to the transformers library. Specifically, the path can be one of the
            following:
                * a model identifier/path that is known to the HuggingFace Hub
                * a directory containing a persisted checkpoint, which may contain either a regular pretrained model
                  or a PEFT model (in which case adapter_config.json must be present in the directory)
                * a directory containing an ONNX model or pair of directories containing ONNX models
                  (with/without history) as generated by ONNXConverter
                  (in which case either model.onnx or model_quantized.onnx must be present)
            If not specified, the base model will be loaded.
        :param transformation: an optional model transformation (which overrides any transformation that was
            given at construction)
        :return: the model
        """
        transformation = transformation if transformation is not None else self.transformation
        automodel_kwargs = {} if transformation is None else transformation.automodel_kwargs()

        model_dir = Path(model_path)
        is_dir = model_dir.is_dir()
        peft_adapter_path = model_dir / "adapter_config.json"
        onnx_path = self._find_onnx_model(model_dir)
        onnx_submodel_without_past_dir = model_dir / "model_without_past"
        onnx_submodel_with_past_dir = model_dir / "model_with_past"

        # PEFT model
        if is_dir and peft_adapter_path.exists():
            log.info(f"Loading base model '{self.base_model_id}'")
            base_model = AutoModelForCausalLM.from_pretrained(self.base_model_id, trust_remote_code=True,
                **automodel_kwargs)
            log.info(f"Loading PEFT model from {model_path}")
            model = PeftModel.from_pretrained(base_model, model_path)

        # single ONNX model
        elif is_dir and onnx_path is not None:
            log.info(f"Loading ONNX model from {onnx_path}")
            decoder_session, decoder_with_past_session = ORTModelForCausalLM.load_model(onnx_path,
                decoder_with_past_path=None, provider="CPUExecutionProvider")
            config = AutoConfig.from_pretrained(model_path)
            model = ORTModelForCausalLM(decoder_session, config, [onnx_path], use_cache=False,
                use_io_binding=False)

        # dual ONNX models (with and without past) in subdirectories
        elif is_dir and (onnx_submodel_without_past_dir.is_dir() and onnx_submodel_with_past_dir.is_dir()):
            submodel_without_past = self._find_onnx_model(onnx_submodel_without_past_dir)
            submodel_with_past = self._find_onnx_model(onnx_submodel_with_past_dir)
            if submodel_without_past is None or submodel_with_past is None:
                raise Exception(f"Did not find ONNX models in [{onnx_submodel_without_past_dir}, {onnx_submodel_with_past_dir}]")
            onnx_paths = [submodel_without_past, submodel_with_past]
            decoder_session, decoder_with_past_session = ORTModelForCausalLM.load_model(onnx_paths[0],
                decoder_with_past_path=onnx_paths[1], provider="CPUExecutionProvider")
            config = AutoConfig.from_pretrained(onnx_submodel_without_past_dir)
            model = ORTModelForCausalLM(decoder_session, config, onnx_paths, use_cache=True,
                use_io_binding=False, decoder_with_past_session=decoder_with_past_session)

        # transformers AutoModel
        else:
            model = AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=True, **automodel_kwargs)

        if transformation is not None:
            model = transformation.transform(model)

        return model

    def _find_onnx_model(self, dir: Path) -> Optional[Path]:
        if not dir.is_dir():
            return None
        candidates = list(dir.glob("*.onnx"))
        n = len(candidates)
        if n > 1:
            raise Exception(f"Found more than one onnx file in {dir}: {candidates}")
        elif n == 1:
            return candidates[0]
        else:
            return None


class SantaCoderModelFactory(ModelFactory):
    def __init__(self):
        super().__init__(base_model_id="bigcode/santacoder")



